{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Logistic Regression\n",
    "\n",
    "In this notebook we train a logistic regression classifier. The purpose is two-fold, to have a baseline classification to compare and to evaluate some of the feature engineering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from process_data import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Original data set with minor data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = train.ix[:,:-1], train.ix[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test, Y_test = test.ix[:,:-1], test.ix[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression with Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio = 0.6866115388897356 --> auc_roc = 0.776399\n",
      "l1_ratio = 0.8016197177628893 --> auc_roc = 0.776800\n",
      "l1_ratio = 0.11353408975563128 --> auc_roc = 0.774496\n",
      "l1_ratio = 0.11858459946208322 --> auc_roc = 0.774518\n",
      "l1_ratio = 0.6722386791640659 --> auc_roc = 0.776319\n",
      "l1_ratio = 0.685400847619186 --> auc_roc = 0.776396\n",
      "l1_ratio = 0.9157647804499023 --> auc_roc = 0.777335\n",
      "l1_ratio = 0.4138875106123888 --> auc_roc = 0.775716\n",
      "l1_ratio = 0.6167556741695351 --> auc_roc = 0.776299\n",
      "l1_ratio = 0.5361370994140355 --> auc_roc = 0.775769\n"
     ]
    }
   ],
   "source": [
    "lg_classifiers = [] # list [[lg, score]]\n",
    "for i in range(10):\n",
    "    c = np.random.rand()\n",
    "    lg = ElasticNetCV(l1_ratio=c, \n",
    "                      n_alphas=200, \n",
    "                      max_iter=2000, \n",
    "                      #tol=1e-4, \n",
    "                      normalize=True)\n",
    "    lg.fit(X_train,Y_train)\n",
    "    Y_pred = lg.predict(X_test)\n",
    "    score = roc_auc_score(Y_test,Y_pred)\n",
    "    lg_classifiers.append([lg, score])\n",
    "    print('l1_ratio = {:.9f} --> auc_roc = {:.6f}'.format(c, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the $l^1$-ratios with better performance are close to 1, we try to find a better ratio using a small perturbation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio = 0.9075163307400439 --> auc_roc = 0.777294\n",
      "l1_ratio = 0.9727656375037396 --> auc_roc = 0.777528\n",
      "l1_ratio = 0.8330539479068436 --> auc_roc = 0.776846\n",
      "l1_ratio = 0.8832114385072016 --> auc_roc = 0.777159\n",
      "l1_ratio = 0.8868300892944662 --> auc_roc = 0.777180\n",
      "l1_ratio = 0.841417195642955 --> auc_roc = 0.776911\n",
      "l1_ratio = 0.8904570981468333 --> auc_roc = 0.777201\n",
      "l1_ratio = 0.8171150458225659 --> auc_roc = 0.776901\n",
      "l1_ratio = 0.9968749834019057 --> auc_roc = 0.777693\n",
      "l1_ratio = 0.9392125041743142 --> auc_roc = 0.777350\n"
     ]
    }
   ],
   "source": [
    "lg_classifiers = [] # list [[lg, score]]\n",
    "for _ in range(10):\n",
    "    c = 1 - 0.2*np.random.rand()\n",
    "    lg = ElasticNetCV(l1_ratio=c, \n",
    "                      n_alphas=200, \n",
    "                      max_iter=2000, \n",
    "                      #tol=1e-4, \n",
    "                      normalize=True)\n",
    "    lg.fit(X_train,Y_train)\n",
    "    Y_pred = lg.predict(X_test)\n",
    "    score = roc_auc_score(Y_test,Y_pred)\n",
    "    lg_classifiers.append([lg, score])\n",
    "    print('l1_ratio = {:9.f} --> auc_roc = {:.6f}'.format(c, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the classifiers for later use\n",
    "pickle.dump(lg_classifiers, open(\"models/lg_classifier_param1.dat\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Data with 'saldo' Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_saldo = pd.read_csv('data/train_extended_saldo.csv')\n",
    "# data already \"processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# New feature counting zero entries\n",
    "original_features = data.columns[:-1]\n",
    "data.insert(len(original_features),'SumZeros',(data[original_features] == 0).sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# New feature describing the number of assets\n",
    "asset_features = [name for name in data.columns if 'ind' in name]\n",
    "temp = data[asset_features].sum(axis=1)\n",
    "data.insert(data.shape[1]-1, 'NumAssets', temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data_saldo, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = train.ix[:,:-1], train.ix[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test, Y_test = test.ix[:,:-1], test.ix[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression with Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1 = 0.8219962396887162 --> auc_roc = 0.780461\n",
      "l1 = 0.9828240252074011 --> auc_roc = 0.782009\n",
      "l1 = 0.9754912109211129 --> auc_roc = 0.782059\n",
      "l1 = 0.8915598639758243 --> auc_roc = 0.781197\n",
      "l1 = 0.8055577354579954 --> auc_roc = 0.780244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/.anaconda3/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1 = 0.998665744457267 --> auc_roc = 0.782019\n",
      "l1 = 0.8842628837116838 --> auc_roc = 0.781138\n",
      "l1 = 0.8502035566026913 --> auc_roc = 0.780774\n",
      "l1 = 0.9600876141148942 --> auc_roc = 0.781922\n",
      "l1 = 0.8491149395157815 --> auc_roc = 0.780763\n"
     ]
    }
   ],
   "source": [
    "lg_classifiers = [] # list [[lg, score]]\n",
    "for _ in range(10):\n",
    "    c = 1 - 0.2*np.random.rand()\n",
    "    lg = ElasticNetCV(l1_ratio=c, \n",
    "                      n_alphas=200, \n",
    "                      max_iter=2000, \n",
    "                      #tol=1e-4, \n",
    "                      normalize=True)\n",
    "    lg.fit(X_train,Y_train)\n",
    "    Y_pred = lg.predict(X_test)\n",
    "    score = roc_auc_score(Y_test,Y_pred)\n",
    "    lg_classifiers.append([lg, score])\n",
    "    print('l1_ratio = {:.9f} --> auc_roc = {:.6f}'.format(c, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the classifiers for later use\n",
    "pickle.dump(lg_classifiers, open(\"models/lg_extended_saldo_classifier_param1.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As we can see, the performance increased from ~0.775 to ~0.782. Therefore, the inclusion of the new variables seems to help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Dropping the Old 'saldo' Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_saldo = pd.read_csv('data/train_saldo.csv')\n",
    "# data already \"processed\" and old saldo features dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data_saldo, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = train.ix[:,:-1], train.ix[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test, Y_test = test.ix[:,:-1], test.ix[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression with Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio = 0.9586033793550597 --> auc_roc = 0.791220\n",
      "l1_ratio = 0.8100157769934385 --> auc_roc = 0.790441\n",
      "l1_ratio = 0.8993004744788721 --> auc_roc = 0.790897\n",
      "l1_ratio = 0.8222336070271263 --> auc_roc = 0.790479\n",
      "l1_ratio = 0.952958551306715 --> auc_roc = 0.791193\n",
      "l1_ratio = 0.9943966190662108 --> auc_roc = 0.791415\n",
      "l1_ratio = 0.9867113482390913 --> auc_roc = 0.791372\n",
      "l1_ratio = 0.9295246885593057 --> auc_roc = 0.791032\n",
      "l1_ratio = 0.9253136229778186 --> auc_roc = 0.791028\n",
      "l1_ratio = 0.904533010435251 --> auc_roc = 0.790922\n"
     ]
    }
   ],
   "source": [
    "lg_classifiers = [] # list [[lg, score]]\n",
    "for _ in range(10):\n",
    "    c = 1 - 0.2*np.random.rand()\n",
    "    lg = ElasticNetCV(l1_ratio=c, \n",
    "                      n_alphas=200, \n",
    "                      max_iter=2000, \n",
    "                      #tol=1e-4, \n",
    "                      normalize=True)\n",
    "    lg.fit(X_train,Y_train)\n",
    "    Y_pred = lg.predict(X_test)\n",
    "    score = roc_auc_score(Y_test,Y_pred)\n",
    "    lg_classifiers.append([lg, score])\n",
    "    print('l1_ratio = {:9f} --> auc_roc = {:.6f}'.format(c, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that dropping the old 'saldo' features results in an even bigger increase in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the classifiers for later use\n",
    "pickle.dump(lg_classifiers, open(\"models/lg_saldo_classifier_param1.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
